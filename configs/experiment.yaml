# Experiment presets for the 4 staged combos
# Use via CLI: python invert.py --preset combo_01 --input path/to/image.png
# Or override individual settings: python invert.py --preset combo_01 --steps 500

# Combo 1: W • L2 • Adam • mean_w • 300 steps
# Purpose: Cheapest sanity check, baseline for comparison
combo_01:
  experiment_name: "combo_01_w_l2_meanw_300"
  latent_space: "W"
  loss_type: "l2"
  init_method: "mean_w"
  optimizer: "adam"
  learning_rate: 0.03
  steps: 600
  # output_dir: auto-generated with combo name + image name + timestamp

# Combo 2: W+ • L2 • Adam • mean_w • 300 steps
# Purpose: Flip latent space only (more expressive, per-layer control)
combo_02:
  experiment_name: "combo_02_wplus_l2_meanw_300"
  latent_space: "W+"
  loss_type: "l2"
  init_method: "mean_w"
  optimizer: "adam"
  learning_rate: 0.03
  steps: 600
  # output_dir: auto-generated with combo name + image name + timestamp

# Combo 3: W+ • LPIPS • Adam • mean_w • 600 steps
# Purpose: Change loss to perceptual (better quality, needs more steps)
combo_03:
  experiment_name: "combo_03_wplus_lpips_meanw_600"
  latent_space: "W+"
  loss_type: "lpips"
  init_method: "mean_w"
  optimizer: "adam"
  learning_rate: 0.03
  steps: 600
  # output_dir: auto-generated with combo name + image name + timestamp

# Combo 4: W • LPIPS • Adam • encoder-init • 300 steps
# Purpose: Encoder-based initialization with W space (compatible with e4e/pSp encoders)
# NOTE: Uses pre-trained 1024×1024 encoders (e4e/pSp) with upscaling
#       Images are upscaled 128×128 → 1024×1024, then encoded to W space
# combo_04 is now in a separate folder (combo_04/) for Google Colab
# See combo_04/README.md for instructions

